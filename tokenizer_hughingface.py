# -*- coding: utf-8 -*-
"""tokenizer-hughingface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18HHfVVPJazWM45l7i1wvGGNEmvUGtf1a
"""

!pip install transformers

from transformers import AutoTokenizer

# Load the tokenizer for the sentiment analysis model
checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Example input sentences
raw_inputs = [
    "The sky is clear, and the weather is perfect today.",
    "I dislike the food here; it's awful!"
]

# Tokenize the inputs and return as PyTorch tensors
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)

from transformers import AutoModelForSequenceClassification

# Load the pretrained sentiment analysis model
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

# Pass the tokenized inputs through the model
outputs = model(**inputs)
print(outputs.logits)

import torch

# Apply the SoftMax function to convert logits into probabilities
predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)

# Retrieve label mapping from the model configuration
labels = model.config.id2label
print(labels)

# Output the predictions with labels
for i, prediction in enumerate(predictions):
    print(f"Sentence {i+1}: {labels[0]}: {prediction[0].item():.4f}, {labels[1]}: {prediction[1].item():.4f}")